---
title: 'Introduction to R: making visuals and exploratory data analysis'
author: "Erin Shellman"
date: "April 4, 2016"
output:
  html_document:
    theme: readable
    toc: yes
    toc_depth: 3
  pdf_document:
    toc: yes
    toc_depth: 2
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(cache = TRUE)
require(dplyr)
require(ggplot2)
require(GGally)
require(scales)
require(lubridate)
```

## Preparation 

### Strap in!

Exploratory data analysis (EDA) is the second step of the data mining process, 
and it's a perfect way to get acquainted with our tools. This notebook is a 
guide to help you get started with R. It's inevitably incomplete, so get 
ready to Google! For those who are new to R, new to working with data, new to 
programming, or all three please keep in mind:

> Whenever you’re learning a new tool, for a long time you’re going to suck… 
> But the good news is that is typical, that’s something that happens to 
> everyone, and it’s only temporary.

That's sage advice from 
[Hadley Wickham](http://www.r-bloggers.com/hadley-wickhams-dplyr-tutorial-at-user-2014-part-1/), 
a statistician and software developer who has revolutionized the way that people 
analyze data with R. We're going to use many of his packages in this class, 
and you'll be a pro in no time.

## R Basics

### Basic calculation

You can use R just like a calculator. It's so intuitive I probably don't have 
to tell you, but I will anyway! Here's all the arithmetic operators you can use:

| Operator | Behavior |
|-----+-------|
| +  | Add scalar values or vectors |
| -  | Subtract scalar values or vectors  |
| *  | Multiply scalar values or vectors |
| /  | Divide scalar values or vectors  |
| ^  | exponentiate scalar values or vectors |
| %%  | modulo on scalar values or vectors |
| %/%  | integer division on scalar values or vectors |

You can type things like this right into R:

```{r 23+45}
23 + 45
value = (4.59 / 0.1)^3
print(value)

# the coolest part is that R will do these operations element-wise on vectors
vector1 = c(1, 2, 3, 4)
vector2 = c(2, 2, 2, 2) # 'c' is short for Concatenate

vector1 + vector2
vector1 * vector2
vector1^2
```

### Test your knowledge

1. If `x = 3` and `y = 8` what is $x^{y}$?
2. 

### Data structures

R has four primary data structures:

* vectors (or arrays)
* matrices
* data frames
* lists

#### Vectors

Vectors are one-dimensional structures that contain data of the same type. 
For example `age = c(18, 30, 27, 59)` is a *numeric* vector and 
`relationship = c('sister', 'aunt', 'nephew')` is a vector of strings. We can 
convert the *relationship* vector is a special categorical type called a 
*factor* like this, `relationship = factor(c('sister', 'aunt', 'nephew'))`. 
Factors are essential for plotting, and we'll talk about them in more detail 
later on.

#### Matrices

Matrices are just like vectors in two-dimensions. They are defined and
accessed like this:

```{r matrix ex}
my_matrix = matrix(data = c(1, 2, 3, 4, 5, 6), ncol = 3)
my_matrix

# say we want to grab the even numbers.
# we can index into my_matrix like this:
my_matrix[2, ]

# but what if they don't happen to all be in the second row?
my_matrix[(my_matrix %% 2) == 0]

# how'd I do that?!
```

#### Data frames

We're going to focus on data frames for most of this class. Data frames are like 
spreadsheets, they can have column names (*headers*) and can contain data of 
different types, like factors and numerical values. Headers are great because we 
can reference columns by name!

```{r df intro}
# collect two vectors in a data frame
df = data.frame(age = c(10, 20, 45, 37),
                relationship = c('sister', 'cousin', 'father', 'aunt'))
df

# use '$' to select a column by name
df$relationship

# 'mean' is a built-in R function
mean(df$age)

# or 
mean(df[ , 'age'])
```

#### Lists

We won't use lists much in this class, but they're pretty useful. Lists
are collections of objects indexed by a key. The stuff inside of a list doesn't
need to be the same dimensions or type, and that makes lists a convenient data
structure for storing collections of related items:

```{r list intro}
my_list = list(value = 1, array = c(1,2), another_array = 1:5)
my_list

# get the list keys
names(my_list)
my_list$array
```

I use lists most often when I'm computing something in batches and want to 
store the output in an intermediate object before, say, combining all the 
results. For example, maybe I'm fitting a monthly forecast and I have three 
years of data. I could write a function that does something like this:

```{r loop/list, eval = FALSE}
while I still have data left:
  loop through data month-by-month:
    fit model
    results[month] = fitted model
    return(results)
```

Then, at the end of this code I've got a list, indexed by month, that contains
all my models and their associated attributes.

### Reading in data

There're lots of ways to read data into R, but in this class 
you can get away with always copying/pasting this:

```{r read data code skeleton, eval = FALSE}
# set your working directory - normally where you data are
setwd('path/to/your/data')

data = read.delim('data.file',
                  header = TRUE,
                  sep = '\t')
```

Type `?read.delim` to learn what the `header` and `sep` arguments do.

To get acquainted, we'll use a data set called *diamonds*, that comes with the
*ggplot2* package. It's a data set containing physical characteristics and prices 
of about 54,000 diamonds. Loading pre-loaded data in R is simple:

```{r diamonds data load and help}
help(diamonds)
data(diamonds)
```

Once data are loaded, there are tons of ways to spot-check it:
```{r diamonds data explore} 
dim(diamonds) # print dimensions
names(diamonds) # print column names
str(diamonds) # data STRucture
head(diamonds, 3) # print top 3 rows 
tail(diamonds, 3) # print bottom 3 rows
summary(diamonds) # summarize the columns
```

### Installing and loading packages

One of the greatest strengths of R is the active community that creates powerful
tools and releases them publicly as R *packages*. Today we'll learn about two 
powerful packages, *ggplot2* and *dplyr*. We'll use *ggplot2* to elegantly 
create rich visualizations and *dplyr* to quickly aggregate and summarize data.

Packages are easy to install and load:
```{r how-to load packages, message = FALSE, eval = FALSE}
# install
install.packages('dplyr', dependencies = TRUE)
install.packages('ggplot2', dependencies = TRUE)
install.packages('GGally', dependencies = TRUE)
install.packages('scales', dependencies = TRUE)
install.packages('lubridate', dependencies = TRUE)

# load
library(dplyr)
library(ggplot2)
```

### Slicing and dicing

Matrices and data frames are indexed `df[row, col]`.  Leaving either the `row` or `col` 
element blank tells R to take all rows, or all columns. There are many ways to 
slice up data frame in R for example:
```{r diamonds slice/dice}
# 1. grab a column by name and assign to edu
price = diamonds[15:20, 'price']
print(price)

# 2. or use the $ to grab the whole column
price = diamonds$price
head(price)

# 3. we can even combine the two to get rows 15 - 20 of the Education column
price = diamonds[15:20, ]$price
print(price)

# 4. what if we don't know the row numbers, but we have a condition? 
pricey = subset(diamonds, price > 18800)
print(pricey)

# 5. select just some of the columns with dplyr's 'select' function
library(dplyr)
sub = select(diamonds, carat, cut, price)
head(sub)

# 6. and then we can use dplyr's 'filter' to do the same subsetting we did in 3
filtered = filter(sub, carat > 0.40)
head(filtered)

# 7. what's cool about dplyr is that you can nest those 
head(
  select(
    filter(diamonds, carat > 0.40), 
  carat, cut, price)
)

# 8. or, even cooler, we can use the 'pipe' notation
filter_by_pipe = diamonds %>% filter(carat > 0.40) %>% select(carat, cut, price)
head(filter_by_pipe)

```

### Getting help

#### R docs

You can access documentation for any function in R by typing `help(function_name)` or 
`?(function_name)`. The help files conform to a standard format so that they're easy 
to navigate. You'll probably end up reading the *usage*, *arguments*, *value* 
and *examples* sections most often. The *usage* section describes how to call 
the function, *arguments* lists all the values that can be set in the call, 
*value* describes what information the function call will return to you, and 
*examples* are typically self-contained chunks of code that you can copy and 
paste into the console.

#### The Internets

Sometimes it's faster and easier to get help with Google. The first step of my 
troubleshooting workflow is typing questions literally into Google, with a few specifics about
the language of the solution I'm looking for.  For example, "R ggplot2 how to 
change legend font size" returns the following top 3 links:

1. [Cookbook for R » Legends (ggplot2)](http://www.cookbook-r.com/Graphs/Legends_(ggplot2)/) 
2. [r - increase legend font size ggplot2 - Stack Overflow](http://stackoverflow.com/questions/20407773/increase-legend-font-size-ggplot2)
3. [theme. ggplot2 0.9.2.1](http://docs.ggplot2.org/0.9.2.1/theme.html)

all of which answer the question. The first link is worth bookmarking. 
It's a page of plots with associated code so you can easily find an example that 
looks like what you want. The second is another phenomenal resource 
called Stackoverflow, which is a public forum for asking programming questions and
getting answers from the public. I use this website probably over 50 times a day, and I bet you
will too. The last link is the *ggplot2* documentation that lists all the 
arguments in the `theme()` element, one of which is `legend.text`. If you're new
to R (and even if you're not) you're going to have to look a lot of things up.
If you're stuck, don't spin your wheels, just start typing the problem into 
Google and you might be surprised at how easy it is to find solutions. 

#### Useful links

* http://www.statmethods.net/
* http://adv-r.had.co.nz/
* http://adv-r.had.co.nz/Style.html
* http://www.cookbook-r.com/
* http://stackoverflow.com/questions/tagged/r-faq%20

#### Classmates

Finally, ask your classmates! As a professional data analyst you likely won't
be working alone. If you're stuck, chances are that your classmates are too.
Even if not, sometimes getting a fresh set of eyes on your code is all you need
to find little bugs. Help each other out!

#### Self-check

1. How many diamonds cost less than $500?
2. How many diamonds cost at least $15,000?
3. What is the range of prices for diamonds of color D?

## Graphics

Visuals are the most compelling way to communicate results. At the 
exploratory stage, we generate numerous, relatively low-fidelity figures that
help familiarize the analyst with new data and guide subsequent analyses.
During the exploratory phase, the goal is to generate sensible figures
quickly without fretting over details, however **axes should always be labeled**.

Statistician and artist [Edward Tufte](http://www.edwardtufte.com/tufte/) has 
canonized some fundamental graphics tips to keep in mind as you create your
figures: 

* Highlight comparisons
* Show causality
* Show as much as possible. We'll explore faceting, color, shape, size as 
method to do this.
* Integrate evidence. Where appropriate, include text, numbers, images but only to 
the extent that they enhance the visualization's narrative.
* Figures **always** have labeled axes!! (ok, this one is mine.)

#### Visualization with *ggplot2*

### Introduction

R has three core plotting systems, *base*, *lattice* and *ggplot2*.
In this course we'll use the plotting library *ggplot2* because it 
combines the best parts of the other two plotting systems and uses a consistent 
syntax that makes plot code intuitive and reusable.

If you're familiar with R's `base` graphics then 
[`qplot()`](http://docs.ggplot2.org/0.9.3.1/qplot.html) will seem natural.  Feel 
free to read up on `qplot()` and its uses, but we're going to focus primarily on
the `ggplot` function for constructing graphics.

```{r qplot ex, fig.width = 4, fig.height = 3, fig.cap = 'test caption'}
# quick scatterplot made with qplot
qplot(carat, price, data = diamonds)
```

Plot objects in *ggplot2* are made up of *geoms* and *aesthetics*. Geometric 
objects, or *geoms*, describe the type of plot, *e.g.* scatter or boxplot. 
*aesthetics* describe how to draw the plot *e.g.* color, size or location.

Every ggplot starts with a line like this:
  `ggplot(dataframe, aes(x = var1, y = var2, ...))` 
that maps data onto x and y dimensions for our plot, yet to be defined.

```{r ggplot scatter, fig.width = 4, fig.height = 3}
# scatter plot
ggplot(diamonds, aes(x = carat, y = price)) +
  # data mapping
  geom_point(alpha = 0.10) + # draw a scatter plot
  # plot labeling
  scale_x_continuous('Carat') +
  scale_y_continuous('Price (USD)') + 
  # theme elements
  ggtitle('Are higher carat more expensive?') + 
  theme_minimal() + # simpler colors. how does it look if you remove it?
  theme(
    axis.text.x = element_text(size = 13),
    axis.text.y = element_text(size = 13),
    title = element_text(size = 12),
    axis.title = element_text(size = 15),
    axis.ticks = element_blank())

# scatter plot
ggplot(diamonds, aes(x = carat, y = price)) +
  # data mapping
  geom_hex() + # draw a scatter plot
  # plot labeling
  scale_x_continuous('Carat') +
  scale_y_continuous('Price (USD)') + 
  # theme elements
  ggtitle('Are higher carat more expensive?') + 
  theme_minimal() + # simpler colors. how does it look if you remove it?
  theme(
    axis.text.x = element_text(size = 13),
    axis.text.y = element_text(size = 13),
    title = element_text(size = 12),
    axis.title = element_text(size = 15),
    axis.ticks = element_blank())
```

Think of *ggplot*s as being built up as layers. First we map the variables with 
the `ggplot` statement, then we tell ggplot what type of plot to make 
(e.g. scatter, histogram, bar plot, etc).  Finally, we can layer on nice labels, 
colors and annotation.  I highly recommend having this page up when plotting: 
<http://docs.ggplot2.org/>

```{r ggplot histogram, fig.width = 4, fig.height = 3, warning = FALSE}
# histogram
ggplot(diamonds, aes(x = price)) +
  # data mapping
  geom_histogram(fill = 'steelblue') + # 
  # plot labeling
  scale_x_continuous('Price') +
  scale_y_continuous('Counts') + 
  # theme elements
  ggtitle("What's the distribution of prices?") + 
  theme_minimal() + 
  theme(
    axis.text.x = element_text(size = 13),
    axis.text.y = element_text(size = 13),
    title = element_text(size = 12),
    axis.title = element_text(size = 15),
    axis.ticks = element_blank())
```

See how much of that code we were able to reuse?

### Aesthetics 

When you want to change a feature of your figure based on the value of another 
variable, you use aesthetics. Unlike the histogram above, where we could specify
the color explicitly in the *geom()*, when the color depends on the value of a
variable, it goes inside `aes()`.

```{r adjusting aes}
ggplot(diamonds, aes(x = carat, y = price)) +
  # data mapping
  geom_point(aes(color = factor(color)), alpha = 0.40) + # draw a scatter plot
  # plot labeling
  scale_x_continuous('Carat') +
  scale_y_continuous('Price (USD)') +
  scale_color_discrete('Color') + # legend title
  # theme elements
  theme_minimal() +
  theme(
    axis.text.x = element_text(size = 13),
    axis.text.y = element_text(size = 13),
    title = element_text(size = 12),
    axis.title = element_text(size = 15),
    axis.ticks = element_blank())
```

### Factors

We used a new function called `factor` in the plot above when describing how to 
color the points. A `factor` is a variable type in R that represents 
categorical data, in this case the color of a diamond. Factor variables are 
very handy in *ggplot2* because they allow us to quickly change color, shape,
facet and many other graphical features by the value of a category. Let's try it
with facets.

### Faceting 

Our colorful carat plot looks pretty good, but there are a lot of points laying 
on top of each other. When you want to compare plots across groups separately 
you can use a *facet* to split the figure up by category.

```{r factors/faceting}
ggplot(diamonds, aes(x = carat, y = price)) +
  # data mapping
  geom_point(alpha = 0.30) + # draw a scatter plot
  geom_smooth(method = 'lm') + 
  facet_wrap(~ cut) +
  # plot labeling
  scale_x_continuous('Carat') +
  scale_y_continuous('Price (USD)') +
  scale_color_discrete('Color') + # legend title
  # theme elements
  theme_minimal() +
  theme(
    axis.text.x = element_text(size = 13),
    axis.text.y = element_text(size = 13),
    title = element_text(size = 12),
    axis.title = element_text(size = 15),
    axis.ticks = element_blank())
```

Now we can view every grouping individually. Notice how we were able to add a 
smoother to the plot and `facet_wrap` elegantly applied it to each sub-plot.
How about with bar plots?

```{r facet_wrap}
ggplot(diamonds, aes(clarity, fill = factor(cut))) + 
  geom_bar() +
  facet_wrap(~ cut) +     
  # plot labeling
  scale_x_discrete('Clarity') +
  scale_y_continuous('Count') +
  scale_fill_discrete('Cut') + # legend title
  # theme elements
  theme_minimal() +
  theme(
    axis.text.x = element_text(size = 6),
    title = element_text(size = 12),
    axis.title = element_text(size = 15),
    axis.ticks = element_blank())
```

### Annotation

Annotation on a figure can add clarity and help the audience understand the 
message.  A lot of these features are not necessary for exploratory analyses,
but can be very helpful for communicating final results. For example, suppose 
we're interested in characterizing the joint distributions of carats and cuts.
These distributions are bumpy and highly right-skewed, so it's difficult to
ascertain the mean without further annotation.

```{r annotate}
carat_summary = diamonds %>% group_by(cut) %>% summarize(carat_mean = round(mean(carat), 2))

ggplot(diamonds, aes(x = factor(cut), y = carat)) +
  geom_violin(fill = "grey80", colour = "#3366FF") +
  geom_text(data = carat_summary, aes(label = carat_mean, x = cut, y = carat_mean)) +
  geom_hline(yintercept = range(carat_summary$carat_mean), alpha = 0.4, linetype = 2) +
  coord_flip() +
  # plot labeling
  scale_x_discrete('Cut') +
  scale_y_continuous('Carat') +
  scale_fill_discrete('Cut') + # legend title
  # theme elements
  theme_minimal() +
  theme(
    axis.text.x = element_text(size = 13),
    axis.text.y = element_text(size = 13),
    title = element_text(size = 12),
    axis.title = element_text(size = 15),
    axis.ticks = element_blank())
```

Ignoring the quick aggregation we did for now, we used `geom_text` to write the
mean carat of each cut on top of the violin plot. Also we drew the range of those
means using `geom_hline` which lets us quickly assess the spread in means. We'll
talk about that cool aggregation step in detail in the next section.

#### Self-check

1. Spend some time exploring the [ggplot2 docs](http://docs.ggplot2.org/current/)
and try out some new figures. What did you learn from your figure?
    
## Exploratory data analysis

### Capital Bikeshare

The *diamonds* data set was a good warm-up, but let's dive into data set we'll be 
working with for the first three weeks of class. These data are from Washington
D.C.'s bikeshare program in 2012, and are split into three files. The first file 
called 
[*usage_2012.tsv*](https://s3-us-west-2.amazonaws.com/bi-tech-cp303/project+1/capital-bike-share/usage_2012.tsv) contains each rental event. The second file, called 
[*daily_weather.tsv*](https://s3-us-west-2.amazonaws.com/bi-tech-cp303/project+1/capital-bike-share/daily_weather.tsv)
, contains normalized DC weather data from 2012. Finally
[*stations.tsv*](https://s3-us-west-2.amazonaws.com/bi-tech-cp303/project+1/capital-bike-share/stations.tsv) 
contains geographical data about the stations like lat/long as 
well as counts of nearby amenities and road features. Let's go through a quick 
exploratory data analysis of the usage data keeping in mind that for the first 
project you'll need to:

1. formalize the business problem as a data mining process
2. *create* the outcome(s) variables (*e.g.* rentals per day)
3. use *aggregation* and *summaries* to create model inputs

```{r EDA load data, eval = FALSE}
usage = read.delim('usage_2012.tsv',
                   sep = '\t',
                   header = TRUE)

weather = read.delim('daily_weather.tsv',
                   sep = '\t',
                   header = TRUE)
```

```{r, echo = FALSE}
setwd('~/projects/BI-TECH-CP303/projects/project 1')
usage = read.delim('./data/usage_2012.tsv',
                   sep = '\t',
                   header = TRUE)

stations = read.delim('./data/stations.tsv',
                   sep = '\t',
                   header = TRUE)

weather = read.delim('./data/daily_weather.tsv',
                   sep = '\t',
                   header = TRUE)
```

Spend some time looking over the data and getting a sense for what types of 
information are available. When I scan over a data set I create small hypotheses 
in my mind and think about the data I'd need to disprove them. For example, 
I see a dummy variable called *is_holiday*, I wonder if the number of rentals is
higher on holidays? 

The data are basically ready to go (*you're welcome*), but lets use the 
*lubridate* package to convert our timestamps to date objects so that we can 
do lots convenient things like subtract dates.

```{r lubridate}
library(lubridate)

is(usage$time_start) # time_start is a factor

usage$time_start = ymd_hms(usage$time_start)
usage$time_end = ymd_hms(usage$time_end)

is(usage$time_start) # And now it's POSIXct (a date)
```

We can use `head(usage)` to start inspecting the data. We have a bike id, start 
and end times and locations, customer type and lots of data about the season and
the weather. Let's start exploring and see if we can make any preliminary 
observations.

```{r EDA prelim data checks, fig.width = 4, fig.height = 3}
# How many unique bikes are there?
length(unique(usage$bike_id))

# How many unique stations are there?
length(unique(usage$station_start))

# What's the temperature distribution like?
summary(weather$temp)
ggplot(weather, aes(x = temp)) +
  geom_density() +
  theme_minimal()

ggplot(weather, aes(x = humidity)) +
  geom_density() +
  theme_minimal()
```

### *ggpairs*

It's going to take forever to discover patterns like this. Fortunately we can 
use the `ggpairs` function in the *GGally* package to plot continuous variables 
all at once.

```{r EDA ggpairs}
library(GGally)
ggpairs(weather[ , c('temp', 'subjective_temp', 'humidity', 'windspeed')])
```

We can customize the upper and lower quadrants and the diagonal. Let's make 
scatter plots with a linear smoother on the lower half, correlation values on 
the upper half, and bar plots on the diagonal. Spend some time staring at the 
plot and make sure you understand how it's read.

```{r ggpairs analysis removed, message = FALSE, warning = FALSE}
# ggpairs(weather[ , c('temp', 'subjective_temp', 'humidity', 'windspeed')],
#           lower = list(continuous = 'smooth', params = c(color = 'steelblue', alpha = 0.60)),
#           diag = list(continuous = 'bar', params = c(fill = '#AAB6A2')), 
#           upper = list(continuous = 'cor', params = list(corSize = 4)), 
#         axisLabels = 'show') +
# theme(legend.position = 'none', 
#         panel.grid.major = element_blank(), 
#         axis.ticks = element_blank(),
#         panel.border = element_blank())

# ggpairs(weather[ , c('temp', 'subjective_temp', 'humidity', 'windspeed')],
#           lower = list(continuous = 'smooth', params = c(color = 'steelblue', alpha = 0.60)),
#           diag = list(continuous = 'bar', params = c(fill = '#AAB6A2')), 
#           upper = list(continuous = 'cor', params = list(corSize = 4)), 
#         axisLabels = 'show') +
# theme(legend.position = 'none', 
#         panel.grid.major = element_blank(), 
#         axis.ticks = element_blank(),
#         panel.border = element_blank())
# 
# ggpairs(swiss[1:4], lower = list(continuous = wrap(my_fn, method="lm")))

```

Immediately we can see that there's a strong linear relationship between the
actual temperature and the subjective temperature. It would be a red flag if 
there wasn't! Similarly there is a negative relationship between humidity and 
wind speed suggesting that when it's more humid, it's less
windy. 

We can do faceting in *ggpairs* plots just like we did with *ggplot2*. The 
figure below is faceted by the season:

```{r additional ggpairs, message = FALSE, warning = FALSE, eval = FALSE}
ggpairs(weather[ , c('temp', 'humidity', 'windspeed', 'season_desc')],
        lower = list(continuous = 'points', combo = 'facetdensity', params = list(alpha = 0.70)),
        diag = list(continuous = 'density', params = list(size = 0.75, alpha = 0.70)), 
        upper = list(continuous = 'cor', combo = 'facetdensity'),
        axisLabels = 'show', color = 'season_desc')

# make sure weather_code is a factor, not numeric
weather$weather_code = factor(weather$weather_code)
ggpairs(weather[ , c('temp', 'humidity', 'windspeed', 'weather_code')],
        lower = list(continuous = 'points', combo = 'facetdensity', params = list(alpha = 0.70)),
        diag = list(continuous = 'density', params = list(size = 0.75, alpha = 0.70)), 
        upper = list(continuous = 'cor', combo = 'facetdensity'),
        axisLabels = 'show', color = 'weather_code')
```

Again we have marginal densities on the diagonal, broken up by season. Not 
surprisingly there's 4 distinct temperature distributions. We can also see that
there's a relationship between 

### Aggregation and summarization with *dplyr*

In any analysis we use aggregation techniques to summarize and compress data.
We can also use aggregation to create new variables, and that's something you'll
need to do in your first project. We got a preview of *dplyr* in the violin 
plot, but we were really just scratching the surface of it's capabilities.

Here's all the [*dplyr* verbs](http://cran.rstudio.com/web/packages/dplyr/vignettes/introduction.html):

* `filter()` and `slice()`
* `arrange()`
* `select()` and `rename()`
* `distinct()`
* `mutate()` and `transmute()`
* `summarise()`
* `sample_n()` and `sample_frac()`

These verbs are linked together either by nesting, or by using 'pipes.' The 
*dplyr* pipe (originally from a package called [*magrittr*](http://seananderson.ca/2014/09/13/dplyr-intro.html)),
allows you to string operations together without saving the intermediate outputs.
It is an extremely powerful method of aggregating and summarizing data.

Ultimately, we want to predict the success of a station, how should we represent
'success?' Could try number of rentals per day.

```{r EDA dplyr getting started, warning = FALSE}
# almost!
custs_per_day = usage %>% group_by(as.Date(time_start)) %>% summarize(no_rentals = n())
head(custs_per_day)

# yes! also note that we can name the colums inside the group_by
custs_per_day = usage %>% 
  group_by(time_start = as.Date(time_start), station_start) %>% 
  summarize(no_rentals = n()) %>%
  ungroup() %>%
  arrange(time_start, desc(no_rentals), station_start) %>%
  na.omit()

head(custs_per_day)

# let plot the top stations
library(scales) # this package gives us pretty date formatting

top_stations = custs_per_day[1:5, ]$station_start
top_stations_to_plot = filter(custs_per_day, station_start %in% top_stations)

ggplot(top_stations_to_plot, aes(x = as.Date(time_start), y = no_rentals)) + 
  geom_line(aes(color = factor(station_start)), alpha = 0.6) +
  theme_minimal() + 
  scale_x_date('Date') +
  scale_y_continuous('Number of Rentals') +
  scale_color_discrete('Station') +
  theme(
    axis.text.x = element_text(size = 13),
    axis.text.y = element_text(size = 13),
    title = element_text(size = 12),
    axis.title = element_text(size = 15),
    axis.ticks = element_blank(),
    legend.position = 'top')

# Maybe we want average daily rentals?
mean_custs_per_day = custs_per_day %>% 
  group_by(station_start) %>% 
  summarize(mean_rentals = mean(no_rentals))

head(mean_custs_per_day)

ggplot(mean_custs_per_day, aes(x = station_start, y = mean_rentals)) +
  geom_bar(stat = 'identity') +
  coord_flip()

ggplot(na.omit(mean_custs_per_day), aes(x = reorder(station_start, mean_rentals), y = mean_rentals)) +
  geom_bar(stat = 'identity') +
  coord_flip()

ggplot(na.omit(filter(mean_custs_per_day, mean_rentals > 80)), 
       aes(x = reorder(station_start, mean_rentals), y = mean_rentals)) +
  geom_bar(stat = 'identity') +
  coord_flip()
```

Clearly some stations are more successful than others. It's your job in project 
1 to determine if station success can be predicted by these data.

#### Self-check

1. Use combinations of the *dplyr* verbs to familiarize yourself with the data.
Are you able to identify any interesting patterns?
2. Make plots of your data explorations with *ggplot2*.
3. We'll learn how to merge data sets next week, but if you're feeling up to it
check out the `merge` function. What are the *keys* that link the three data sets
together?

** Save your code! **