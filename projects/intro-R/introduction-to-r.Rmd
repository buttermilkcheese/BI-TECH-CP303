---
title: 'Introduction to R: making visuals and exploratory data analysis'
author: "Erin Shellman"
date: "April 4, 2016"
output:
  pdf_document:
    toc: yes
    toc_depth: 3
  html_document:
    theme: readable
    toc: yes
    toc_depth: 3
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(cache = TRUE, warning = FALSE, message = FALSE, 
                      error = FALSE, fig.align = 'center')

require(dplyr)
require(ggplot2)
#require(GGally)
#require(scales)
#require(lubridate)

data = read.delim('bikeshare_2015.tsv',
                  header = TRUE,
                  sep = '\t')
```

# Preparation 

## Strap in!

Exploratory data analysis (EDA) is the second step of the data mining process, 
and it's a perfect way to get acquainted with our tools. This notebook is a 
guide to help you get started with R. It's inevitably incomplete, so get 
ready to Google! For those who are new to R, new to working with data, new to 
programming, or all three please keep in mind:

> Whenever you’re learning a new tool, for a long time you’re going to suck… 
> But the good news is that is typical, that’s something that happens to 
> everyone, and it’s only temporary.

That's sage advice from 
[Hadley Wickham](http://www.r-bloggers.com/hadley-wickhams-dplyr-tutorial-at-user-2014-part-1/), 
a statistician and software developer who has revolutionized the way that people 
analyze data with R. We're going to use many of his packages in this class, 
and you'll be a pro in no time.

## R Basics

### Basic calculation

You can use R just like a calculator. It's so intuitive I probably don't have 
to tell you, but I will anyway! Here's all the arithmetic operators you can use:

| Operator | Behavior |
|-----+-------|
| +  | Add scalar values or vectors |
| -  | Subtract scalar values or vectors  |
| *  | Multiply scalar values or vectors |
| /  | Divide scalar values or vectors  |
| ^  | exponentiate scalar values or vectors |
| %%  | modulo on scalar values or vectors |
| %/%  | integer division on scalar values or vectors |

You can type things like this right into R:

```{r calculator examples}
23 + 45
value = (4.59 / 0.1)^3
print(value)

# the coolest part is that R will do these operations element-wise on vectors
vector1 = c(1, 2, 3, 4)
vector2 = c(2, 2, 2, 2) # 'c' is short for Concatenate

vector1 + vector2
vector1 * vector2
vector1^2
```

### Test your knowledge

1. If `x = 3` and `y = 8` what is $x^{y}$?
2. 

### Data structures

R has four primary data structures:

* vectors (or arrays)
* matrices
* data frames
* lists

#### Vectors

Vectors are one-dimensional structures that contain data of the same type. 
For example `age = c(18, 30, 27, 59)` is a *numeric* vector and 
`relationship = c('sister', 'aunt', 'nephew')` is a vector of strings. We can 
convert the *relationship* vector is a special categorical type called a 
*factor* like this, `relationship = factor(c('sister', 'aunt', 'nephew'))`. 
Factors are essential for plotting, and we'll talk about them in more detail 
later on.

#### Matrices

Matrices are just like vectors in two-dimensions. They are defined and
accessed like this:

```{r matrix ex}
my_matrix = matrix(data = c(1, 2, 3, 4, 5, 6), ncol = 3)
my_matrix

# say we want to grab the even numbers.
# we can index into my_matrix like this:
my_matrix[2, ]

# but what if they don't happen to all be in the second row?
my_matrix[(my_matrix %% 2) == 0]

# how'd I do that?!
```

#### Data frames

We're going to focus on data frames for most of this class. Data frames are like 
spreadsheets, they can have column names (*headers*) and can contain data of 
different types, like factors and numerical values. Headers are great because we 
can reference columns by name!

```{r df example}
# collect two vectors in a data frame
df = data.frame(age = c(10, 20, 45, 37),
                relationship = c('sister', 'cousin', 'father', 'aunt'))
df

# use '$' to select a column by name
df$relationship

# 'mean' is a built-in R function
mean(df$age)

# or 
mean(df[ , 'age'])
```

#### Lists

We won't use lists much in this class, but they're pretty useful. Lists
are collections of objects indexed by a key. The stuff inside of a list doesn't
need to be the same dimensions or type, and that makes lists a convenient data
structure for storing collections of related items:

```{r list ex}
my_list = list(value = 1, array = c(1,2), another_array = 1:5)
my_list

# get the list keys
names(my_list)
my_list$array
```

I use lists most often when I'm computing something in batches and want to 
store the output in an intermediate object before, say, combining all the 
results. For example, maybe I'm fitting a monthly forecast and I have three 
years of data. I could write a function that does something like this:

```{r list/loop ex, eval = FALSE}
while I still have data left:
  loop through data month-by-month:
    fit model
    results[month] = fitted model
    return(results)
```

Then, at the end of this code I've got a list, indexed by month, that contains
all my models and their associated attributes.

### Reading in data

There're lots of ways to read data into R, but in this class 
you can get away with always copying/pasting this:

```{r set path/load data package skeleton, eval = FALSE}
# set your working directory - normally where you data are
setwd('path/to/your/data')

data = read.delim('data.file',
                  header = TRUE,
                  sep = '\t')
```

Type `?read.delim` to learn what the `header` and `sep` arguments do.

To get acquainted, we'll use a data set called *diamonds*, that comes with the
*ggplot2* package. It's a data set containing physical characteristics and prices 
of about 54,000 diamonds. Loading pre-loaded data in R is simple:

Once data are loaded, there are tons of ways to spot-check it:
```{r diamonds load and help}
help(diamonds)
data(diamonds)
```

Once data are loaded, there are tons of ways to spot-check it:
```{r diamonds bkgd EDA} 
dim(diamonds) # print dimensions
names(diamonds) # print column names
str(diamonds) # data STRucture
head(diamonds, 3) # print top 3 rows 
tail(diamonds, 3) # print bottom 3 rows
summary(diamonds) # summarize the columns
```


### Slicing and dicing

Matrices and data frames are indexed `df[row, col]`.  Leaving either the `row` or `col` 
element blank tells R to take all rows, or all columns. There are many ways to 
slice up data frame in R for example:

```{r diamonds slice/dice}
# 1. grab a column by name and assign to edu
price = diamonds[15:20, 'price']
print(price)

# 2. or use the $ to grab the whole column
price = diamonds$price
head(price)

# 3. we can even combine the two to get rows 15 - 20 of the Education column
price = diamonds[15:20, ]$price
print(price)

# 4. what if we don't know the row numbers, but we have a condition? 
pricey = subset(diamonds, price > 18800)
print(pricey)

# 5. select just some of the columns with dplyr's 'select' function
library(dplyr)
sub = select(diamonds, carat, cut, price)
head(sub)

# 6. and then we can use dplyr's 'filter' to do the same subsetting we did in 3
filtered = filter(sub, carat > 0.40)
head(filtered)

# 7. what's cool about dplyr is that you can nest those 
head(
  select(
    filter(diamonds, carat > 0.40), 
  carat, cut, price)
)

# 8. or, even cooler, we can use the 'pipe' notation
filter_by_pipe = diamonds %>% filter(carat > 0.40) %>% select(carat, cut, price)
head(filter_by_pipe)
```

#### Self-check

1. How many diamonds cost less than $500?
2. How many diamonds cost at least $15,000?
3. What is the range of prices for diamonds of color D?

### Installing and loading packages

One of the greatest strengths of R is the active community that creates powerful
tools and releases them publicly as R *packages*. Today we'll learn about two 
powerful packages, *ggplot2* and *dplyr*. We'll use *ggplot2* to elegantly 
create rich visualizations and *dplyr* to quickly aggregate and summarize data.

Packages are easy to install and load:
```{r load packages, message = FALSE, eval = FALSE}
# install
install.packages('dplyr', dependencies = TRUE)
install.packages('ggplot2', dependencies = TRUE)
install.packages('GGally', dependencies = TRUE)
install.packages('scales', dependencies = TRUE)
install.packages('lubridate', dependencies = TRUE)

# load
library(dplyr)
library(ggplot2)
```

### Getting help

#### R docs

You can access documentation for any function in R by typing `help(function_name)` or 
`?(function_name)`. The help files conform to a standard format so that they're easy 
to navigate. You'll probably end up reading the *usage*, *arguments*, *value* 
and *examples* sections most often. The *usage* section describes how to call 
the function, *arguments* lists all the values that can be set in the call, 
*value* describes what information the function call will return to you, and 
*examples* are typically self-contained chunks of code that you can copy and 
paste into the console.

#### The Internets

Sometimes it's faster and easier to get help with Google. The first step of my 
troubleshooting workflow is typing questions literally into Google, with a few specifics about
the language of the solution I'm looking for.  For example, "R ggplot2 how to 
change legend font size" returns the following top 3 links:

1. [Cookbook for R » Legends (ggplot2)](http://www.cookbook-r.com/Graphs/Legends_(ggplot2)/) 
2. [r - increase legend font size ggplot2 - Stack Overflow](http://stackoverflow.com/questions/20407773/increase-legend-font-size-ggplot2)
3. [theme. ggplot2 0.9.2.1](http://docs.ggplot2.org/0.9.2.1/theme.html)

all of which answer the question. The first link is worth bookmarking. 
It's a page of plots with associated code so you can easily find an example that 
looks like what you want. The second is another phenomenal resource 
called Stackoverflow, which is a public forum for asking programming questions and
getting answers from the public. I use this website probably over 50 times a day, and I bet you
will too. The last link is the *ggplot2* documentation that lists all the 
arguments in the `theme()` element, one of which is `legend.text`. If you're new
to R (and even if you're not) you're going to have to look a lot of things up.
If you're stuck, don't spin your wheels, just start typing the problem into 
Google and you might be surprised at how easy it is to find solutions. 

#### Classmates

Finally, ask your classmates! As a professional data analyst you likely won't
be working alone. If you're stuck, chances are that your classmates are too.
Even if not, sometimes getting a fresh set of eyes on your code is all you need
to find little bugs. Help each other out!

#### Useful links

* http://www.statmethods.net/
* http://adv-r.had.co.nz/
* http://adv-r.had.co.nz/Style.html
* http://www.cookbook-r.com/
* http://stackoverflow.com/questions/tagged/r-faq%20

## Graphics

Visuals are the most compelling way to communicate results. At the 
exploratory stage, we generate numerous, relatively low-fidelity figures that
help familiarize the analyst with new data and guide subsequent analyses.
During the exploratory phase, the goal is to generate sensible figures
quickly without fretting over details, however **axes should always be labeled**.

Statistician and artist [Edward Tufte](http://www.edwardtufte.com/tufte/) has 
canonized some fundamental graphics tips to keep in mind as you create your
figures: 

* Highlight comparisons
* Show causality
* Show as much as possible. We'll explore faceting, color, shape, size as 
method to do this.
* Integrate evidence. Where appropriate, include text, numbers, images but only to 
the extent that they enhance the visualization's narrative.
* Figures **always** have labeled axes!! (ok, this one is mine.)

### Introduction to *ggplot2*

R has three core plotting systems, *base*, *lattice* and *ggplot2*.
In this course we'll use the plotting library *ggplot2* because it 
combines the best parts of the other two plotting systems and uses a consistent 
syntax that makes plot code intuitive and reusable.

Plot objects in *ggplot2* are made up of *geoms* and *aesthetics*. Geometric 
objects, or *geoms*, describe the type of plot, *e.g.* scatter or boxplot. 
*aesthetics* describe how to draw the plot *e.g.* color, size or location.

Every ggplot starts with a line like this:
  `ggplot(dataframe, aes(x = var1, y = var2, ...))` 
that maps data onto x and y dimensions for our plot, yet to be defined. If you 
run the aforementioned plotting code what do you get?

```{r ggplot intro no layers, fig.width = 4, fig.height = 3}
ggplot(diamonds, aes(x = carat, y = price))
```

A blank coordinate system with *x-* and *y-*axis labels. Why? Well, you've 
told ggplot2 how to map data to the coordinates x and y, but you haven't told it
how to draw that mapping. We tell ggplot how to draw using *geoms*.

```{r ggplot intro scatter, fig.width = 4, fig.height = 3}
ggplot(diamonds, aes(x = carat, y = price)) + geom_point()
```

Think of the plots as being built up as layers. First we map the variables with 
the `ggplot` statement, then we tell ggplot what type of plot to make 
(e.g. scatter, histogram, bar plot, etc).

```{r ggplot intro histogram, fig.width = 4, fig.height = 3}
ggplot(diamonds, aes(x = carat)) + geom_histogram()
```

Finally, we can layer on nice labels, 
colors and annotation. I highly recommend having this page up when plotting: 
<http://docs.ggplot2.org/>

```{r ggplot intro title, fig.width = 4, fig.height = 3}
ggplot(diamonds, aes(x = carat, y = price)) +
  geom_point() + 
  scale_x_continuous('Carat') + # axis labels 
  scale_y_continuous('Price ($)') + 
  ggtitle('Are higher carat more expensive?') + 
  theme_minimal() # Themes? Score! How does the plot change w/wo it?
```

```{r ggplot diamond scatter2, fig.width = 4, fig.height = 3}
# scatter plot
ggplot(diamonds, aes(x = carat, y = price)) +
  # data mapping
  geom_point(alpha = 0.10) + # draw a scatter plot
  # plot labeling
  scale_x_continuous('Carat') +
  scale_y_continuous('Price (USD)') + 
  # theme elements
  ggtitle('Are higher carat more expensive?') + 
  theme_minimal() 

# scatter plot
ggplot(diamonds, aes(x = carat, y = price)) +
  # data mapping
  geom_hex() + # draw a scatter plot
  # plot labeling
  scale_x_continuous('Carat') +
  scale_y_continuous('Price (USD)') + 
  # theme elements
  ggtitle('Are higher carat more expensive?') + 
  theme_minimal()
```

```{r ggplot diamond histogram2, fig.width = 4, fig.height = 3}
# histogram
ggplot(diamonds, aes(x = price)) +
  # data mapping
  geom_histogram(fill = 'steelblue') + # 
  # plot labeling
  scale_x_continuous('Price') +
  scale_y_continuous('Counts') + 
  # theme elements
  ggtitle("What's the distribution of prices?") + 
  theme_minimal()
```

If you're familiar with R's `base` graphics then 
[`qplot()`](http://docs.ggplot2.org/0.9.3.1/qplot.html) will seem natural.  Feel 
free to read up on `qplot()` and its uses, but we're going to focus primarily on
the `ggplot` function for constructing graphics.

```{r qplot ex, fig.width = 4, fig.height = 3}
# quick scatterplot made with qplot
qplot(carat, price, data = diamonds)
```

### Aesthetics 

When you want to change a feature of your figure based on the value of another 
variable, you use aesthetics. Unlike the histogram above, where we could specify
the color explicitly in the *geom()*, when the color depends on the value of a
variable, it goes inside `aes()`.

```{r aes in geom ex}
ggplot(diamonds, aes(x = carat, y = price)) +
  geom_point(aes(color = factor(color)), alpha = 0.40) + # draw a scatter plot
  scale_x_continuous('Carat') +
  scale_y_continuous('Price (USD)') +
  scale_color_discrete('Color') + # legend title
  theme_minimal()
```

### Factors

We used a new function called `factor` in the plot above when describing how to 
color the points. A `factor` is a variable type in R that represents 
categorical data, in this case the color of a diamond. Factor variables are 
very handy in *ggplot2* because they allow us to quickly change color, shape,
facet and many other graphical features by the value of a category. Let's try it
with facets.

### Faceting 

Our colorful carat plot looks pretty good, but there are a lot of points laying 
on top of each other. When you want to compare plots across groups separately 
you can use a *facet* to split the figure up by category.

```{r factors and facetting}
ggplot(diamonds, aes(x = carat, y = price)) +
  geom_point(alpha = 0.30) +
  geom_smooth(method = 'lm') + 
  facet_wrap(~ cut) +
  scale_x_continuous('Carat') +
  scale_y_continuous('Price (USD)') +
  scale_color_discrete('Color') +
  theme_minimal() 
```

Now we can view every grouping individually. Notice how we were able to add a 
smoother to the plot and `facet_wrap` elegantly applied it to each sub-plot.
How about with bar plots?

```{r facet_wrap}
ggplot(diamonds, aes(clarity, fill = factor(cut))) + 
  geom_bar() +
  facet_wrap(~ cut) +     
  scale_x_discrete('Clarity') +
  scale_y_continuous('Count') +
  scale_fill_discrete('Cut') + 
  theme_minimal() 
```

<!--### Annotation-->

### Assignment 1

One or two questions that can be answered with a figure and dplyr.

Annotation on a figure can add clarity and help the audience understand the 
message.  A lot of these features are not necessary for exploratory analyses,
but can be very helpful for communicating final results. For example, suppose 
we're interested in characterizing the joint distributions of carats and cuts.
These distributions are bumpy and highly right-skewed, so it's difficult to
ascertain the mean without further annotation.

```{r dplyr+ggplot assignment 1}
carat_summary = diamonds %>% group_by(cut) %>% summarize(carat_mean = round(mean(carat), 2))

ggplot(diamonds, aes(x = factor(cut), y = carat)) +
  geom_violin(fill = "grey80", colour = "#3366FF") +
  geom_text(data = carat_summary, aes(label = carat_mean, x = cut, y = carat_mean)) +
  geom_hline(yintercept = range(carat_summary$carat_mean), alpha = 0.4, linetype = 2) +
  coord_flip() +
  # plot labeling
  scale_x_discrete('Cut') +
  scale_y_continuous('Carat') +
  scale_fill_discrete('Cut') + # legend title
  # theme elements
  theme_minimal()
```

Ignoring the quick aggregation we did for now, we used `geom_text` to write the
mean carat of each cut inside of the violin plot. Also we drew the range of those
means using `geom_hline` which lets us quickly assess the spread in means. We'll
talk about that cool aggregation step in detail in the next section.

#### Self-check

1. Spend some time exploring the [ggplot2 docs](http://docs.ggplot2.org/current/)
and try out some new figures. What did you learn from your figure?
    
## Exploratory data analysis

### Capital Bikeshare

The *diamonds* data was a good warm-up, but let's dive into the data you'll be 
working with in the first project. The data are from Washington
D.C.'s bikeshare program in 2015 and are in the file [*bikeshare_2015.tsv*]() in
the course repository. 

```{r EDA data-read-in, eval = FALSE}
data = read.delim('/your/dir/bikeshare_2015.tsv',
                  header = TRUE,
                  sep = '\t')
```

Read the data in using the `read.delim` function previously described and type 
`head(data)` to inspect the data set. There's a station name, rental duration, 
a count of the number of rentals, lat/long, and lots of information about 
the surrounding environment. Let's start exploring and see if we can make any 
preliminary observations.

Throughout the course you'll be tackling business problems
with data which means you'll need to:

1. formalize the business problem as a data mining process
2. articulate the solution *i.e.* how will you know when you've answered the question?
3. help make a decision, *i.e.* what should the business do?

```{r EDA histogram, fig.width = 4, fig.height = 3, warning = FALSE}
ggplot(data, aes(x = duration_mean)) +
  geom_histogram(fill = 'steelblue') + # 
  scale_x_continuous('Rental Duration') +
  scale_y_continuous('Counts') + 
  ggtitle("What's the distribution of rental times?") + 
  theme_minimal()  
```

Spend some time looking over the data and getting a sense for what types of 
information are available. When I scan over a data set I create small hypotheses 
in my mind and think about the data I'd need to disprove them. For example, 
I see a variable called *traffic_signals*, I wonder if rentals would be lower in
areas with more traffic signals because people don't want to bike around cars? 

```{r EDA ride duration, fig.width = 4, fig.height = 3}
# How many stations are there?
length(data$station)

# What's the ride duration distribution like?
summary(data$duration_mean)

ggplot(data, aes(x = duration_mean)) +
  geom_histogram() + # 
  scale_x_continuous('Ride Duration') +
  scale_y_continuous('Counts') + 
  ggtitle("What's the distribution of rental times?") 

# Is there a relationship between the number of crosswalks nearby and rentals?
ggplot(data, aes(x = crossing, y = num_rentals)) +
  geom_point() 
```

### *ggpairs*

You might have noticed that there are a lot of variables in the data set (if you
didn't try running `dim(data)`). It's going to take forever to discover patterns 
one plot at a time. Fortunately there's a cool function called `ggpairs` 
in the *GGally* package to plot continuous variables as a matrix.

```{r ggpairs ex}
library(GGally) # you might have to install it first
ggpairs(data[ , c('bar', 'restaurant', 'duration_mean', 'num_rentals')])
```

Whoa, what are we looking at here? We have four variables which are shown on 
both the *x-* and *y-*axes. In the lower left corner are scatterplots showing multiple
comparisons. For example, the very bottom left-most tile shows the relationship 
between the number of rentals and the number of nearby bars. The diagonal shows
the marginal distribution of each variable, which shows us that all four variables
are right-skewed (*i.e.* long tail going towards the right). Finally, the top 
right corner shows the correlation of each comparison. For example the correlation
between the number of rentals and number of nearby bars is 0.22.

If you like you can customize the upper and lower quadrants and the diagonal. Let's make 
scatter plots with a linear smoother on the lower half, correlation values on 
the upper half, and bar plots on the diagonal. Spend some time staring at the 
plot and make sure you understand how it's read.

```{r commented out ggpairs code, include = FALSE}
# ggpairs(weather[ , c('temp', 'subjective_temp', 'humidity', 'windspeed')],
#           lower = list(continuous = 'smooth', params = c(color = 'steelblue', alpha = 0.60)),
#           diag = list(continuous = 'bar', params = c(fill = '#AAB6A2')), 
#           upper = list(continuous = 'cor', params = list(corSize = 4)), 
#         axisLabels = 'show') +
# theme(legend.position = 'none', 
#         panel.grid.major = element_blank(), 
#         axis.ticks = element_blank(),
#         panel.border = element_blank())

# ggpairs(weather[ , c('temp', 'subjective_temp', 'humidity', 'windspeed')],
#           lower = list(continuous = 'smooth', params = c(color = 'steelblue', alpha = 0.60)),
#           diag = list(continuous = 'bar', params = c(fill = '#AAB6A2')), 
#           upper = list(continuous = 'cor', params = list(corSize = 4)), 
#         axisLabels = 'show') +
# theme(legend.position = 'none', 
#         panel.grid.major = element_blank(), 
#         axis.ticks = element_blank(),
#         panel.border = element_blank())
# 
# ggpairs(swiss[1:4], lower = list(continuous = wrap(my_fn, method="lm")))

```

<!--TODO: update this.
We can do faceting in *ggpairs* plots just like we did with *ggplot2*. The 
figure below is faceted by the season:-->

```{r ggpairs extended example, eval = FALSE, include = FALSE}
ggpairs(weather[ , c('temp', 'humidity', 'windspeed', 'season_desc')],
        lower = list(continuous = 'points', combo = 'facetdensity', params = list(alpha = 0.70)),
        diag = list(continuous = 'density', params = list(size = 0.75, alpha = 0.70)), 
        upper = list(continuous = 'cor', combo = 'facetdensity'),
        axisLabels = 'show', color = 'season_desc')

# make sure weather_code is a factor, not numeric
weather$weather_code = factor(weather$weather_code)
ggpairs(weather[ , c('temp', 'humidity', 'windspeed', 'weather_code')],
        lower = list(continuous = 'points', combo = 'facetdensity', params = list(alpha = 0.70)),
        diag = list(continuous = 'density', params = list(size = 0.75, alpha = 0.70)), 
        upper = list(continuous = 'cor', combo = 'facetdensity'),
        axisLabels = 'show', color = 'weather_code')
```

Again we have marginal densities on the diagonal, broken up by season. Not 
surprisingly there's 4 distinct temperature distributions. We can also see that
there's a relationship between 

### Assignment 2

1. Make some hypotheses about which variables are likely to be positively and
negatively correlated with `duration_mean` and `num_rentals`. Test your hypotheses
using the plotting and summary methods we've learned so far or by Googling for 
others. 

Solutions: 

correlation of `duration_mean` and `place_of_worship` is -0.24
correlation of `duration_mean` and `artwork_type_statue` is 0.15

correlation of `num_rentals` and `tourism_artwork` is 0.49
correlation of `num_rentals` and `railway_level_crossing` is -0.13

2. Something else.

### Aggregation and summarization with *dplyr*

Virtually any analysis will require aggregation techniques to summarize and 
compress data. Aggregation can also be used to create new variables to explore. 
The package *dplyr* is tied for my personal favorite package in R (with *ggplot2*)
and it is an extremely powerful and elegant way to aggregate, manipulate, tranform,
and generally do awesome stuff with data. We saw a preview of *dplyr* in the 
violin plot, but that was really just scratching the surface of it's capabilities.

*dplyr* is a fast, consistent tool for working with data frame like objects, 
and allows you to 'chain' together SQL-like verbs to quickly and easily manipulate
data.

Here's a list of all the [*dplyr* verbs](http://cran.rstudio.com/web/packages/dplyr/vignettes/introduction.html):

* `filter()` and `slice()`
* `arrange()`
* `select()` and `rename()`
* `distinct()`
* `mutate()` and `transmute()`
* `summarise()`
* `sample_n()` and `sample_frac()`

The verbs are chained together either by nesting, or by using 'pipes.' The 
*dplyr* pipe (originally from a package called [*magrittr*](http://seananderson.ca/2014/09/13/dplyr-intro.html)),
allows you to string operations together without saving the intermediate outputs.
It is an extremely powerful method of aggregating and summarizing data.

```{r EDA dplyr + ggplot2, include = FALSE, eval = FALSE}
# almost!
custs_per_day = usage %>% group_by(as.Date(time_start)) %>% summarize(no_rentals = n())
head(custs_per_day)

# yes! also note that we can name the colums inside the group_by
custs_per_day = usage %>% 
  group_by(time_start = as.Date(time_start), station_start) %>% 
  summarize(no_rentals = n()) %>%
  ungroup() %>%
  arrange(time_start, desc(no_rentals), station_start) %>%
  na.omit()

head(custs_per_day)

# let plot the top stations
library(scales) # this package gives us pretty date formatting

top_stations = custs_per_day[1:5, ]$station_start
top_stations_to_plot = filter(custs_per_day, station_start %in% top_stations)

ggplot(top_stations_to_plot, aes(x = as.Date(time_start), y = no_rentals)) + 
  geom_line(aes(color = factor(station_start)), alpha = 0.6) +
  theme_minimal() + 
  scale_x_date('Date') +
  scale_y_continuous('Number of Rentals') +
  scale_color_discrete('Station') +
  theme(
    axis.text.x = element_text(size = 13),
    axis.text.y = element_text(size = 13),
    title = element_text(size = 12),
    axis.title = element_text(size = 15),
    axis.ticks = element_blank(),
    legend.position = 'top')

# Maybe we want average daily rentals?
mean_custs_per_day = custs_per_day %>% 
  group_by(station_start) %>% 
  summarize(mean_rentals = mean(no_rentals))

head(mean_custs_per_day)

ggplot(mean_custs_per_day, aes(x = station_start, y = mean_rentals)) +
  geom_bar(stat = 'identity') +
  coord_flip()

ggplot(na.omit(mean_custs_per_day), aes(x = reorder(station_start, mean_rentals), y = mean_rentals)) +
  geom_bar(stat = 'identity') +
  coord_flip()

ggplot(na.omit(filter(mean_custs_per_day, mean_rentals > 80)), 
       aes(x = reorder(station_start, mean_rentals), y = mean_rentals)) +
  geom_bar(stat = 'identity') +
  coord_flip()
```

Clearly some stations are more successful than others. It's your job in project 
1 to determine if station success can be predicted by these data.

#### Assignment 3

1. Use combinations of the *dplyr* verbs to familiarize yourself with the data.
Are you able to identify any interesting patterns?

2. Need more specific questions.

** Save your code! **